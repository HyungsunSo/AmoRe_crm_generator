{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "코랩용 기존 파이프라인 vs. 파인튜닝된 파이프라인 비교 스크립트\n",
    "./adapters_dpo에 존재하는 어댑터를 기준으로 GPT-Score / 비GPT-Score를 비교.\n",
    "random_persona_campaign.csv의 더미 데이터를 기준으로 평가함.\n",
    "비교 문서는 adapter_comparison_{timestamp}.md로 저장.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e06164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets peft trl bitsandbytes accelerate\n",
    "!pip install -U transformers\n",
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716bd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jjjh02/AmoRe_crm_generator.git\n",
    "%cd AmoRe_crm_generator\n",
    "!git checkout jinhyeok\n",
    "!git branch\n",
    "os.chdir(\"/content/AmoRe_crm_generator\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(BASE_DIR, \"..\"))\n",
    "SRC_DIR = os.path.join(PROJECT_DIR, \"src\")\n",
    "DEFAULT_CSV = os.path.join(BASE_DIR, \"random_persona_campaign.csv\")\n",
    "DEFAULT_ADAPTER_DIR = os.path.join(BASE_DIR, \"adapters_dpo\")\n",
    "STAGE_ORDER = [\"Acquisition\", \"Activation\", \"Retention\", \"Revenue\", \"Referral\"]\n",
    "\n",
    "\n",
    "def _log(message):\n",
    "    print(message)\n",
    "\n",
    "\n",
    "def _import_pipeline_module():\n",
    "    if SRC_DIR not in sys.path:\n",
    "        sys.path.insert(0, SRC_DIR)\n",
    "    import run_qwen_exaone_pipeline as pipeline_module\n",
    "    return pipeline_module\n",
    "\n",
    "\n",
    "def _load_json(path):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _parse_bool(value):\n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "    if value is None:\n",
    "        return False\n",
    "    if isinstance(value, (int, float)):\n",
    "        return bool(value)\n",
    "    text = str(value).strip().lower()\n",
    "    return text in {\"1\", \"true\", \"yes\", \"y\", \"t\"}\n",
    "\n",
    "\n",
    "def _load_rows(csv_path):\n",
    "    with open(csv_path, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            persona_raw = row.get(\"persona\", \"\").strip()\n",
    "            brand_raw = row.get(\"brand\", \"\").strip()\n",
    "            product_raw = row.get(\"product\", \"\").strip()\n",
    "            stage_raw = row.get(\"stage_index\", \"\").strip()\n",
    "            style_raw = row.get(\"style_index\", \"\").strip()\n",
    "            if not persona_raw or not brand_raw or not product_raw:\n",
    "                continue\n",
    "            if not stage_raw or not style_raw:\n",
    "                continue\n",
    "            try:\n",
    "                persona = int(persona_raw)\n",
    "                stage_index = int(stage_raw)\n",
    "                style_index = int(style_raw)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            yield {\n",
    "                \"persona\": persona,\n",
    "                \"brand\": brand_raw,\n",
    "                \"product\": product_raw,\n",
    "                \"stage_index\": stage_index,\n",
    "                \"style_index\": style_index,\n",
    "                \"is_event\": _parse_bool(row.get(\"is_event\", \"\")),\n",
    "            }\n",
    "\n",
    "\n",
    "def _get_stage_name(stage_index):\n",
    "    if isinstance(stage_index, int) and 0 <= stage_index < len(STAGE_ORDER):\n",
    "        return STAGE_ORDER[stage_index]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _get_crm_goal(crm_goals, stage_index, stage_name=None):\n",
    "    if not isinstance(crm_goals, dict):\n",
    "        return {}\n",
    "    if stage_name and stage_name in crm_goals:\n",
    "        return crm_goals.get(stage_name, {}) or {}\n",
    "    stage_name = _get_stage_name(stage_index)\n",
    "    if stage_name:\n",
    "        return crm_goals.get(stage_name, {}) or {}\n",
    "    return {}\n",
    "\n",
    "\n",
    "def _get_brand_story(brand_stories, brand_name):\n",
    "    if not isinstance(brand_stories, dict) or not brand_name:\n",
    "        return {}\n",
    "    if brand_name in brand_stories:\n",
    "        return brand_stories.get(brand_name, {}) or {}\n",
    "    for story in brand_stories.values():\n",
    "        if str(story.get(\"name_en\", \"\")).lower() == brand_name.lower():\n",
    "            return story\n",
    "    return {}\n",
    "\n",
    "\n",
    "def _format_event(selected_event):\n",
    "    if selected_event in (None, \"\", {}):\n",
    "        return \"none\"\n",
    "    if isinstance(selected_event, dict):\n",
    "        for key in (\"title\", \"name\", \"event_name\", \"event\"):\n",
    "            if selected_event.get(key):\n",
    "                return str(selected_event.get(key))\n",
    "        return json.dumps(selected_event, ensure_ascii=False)\n",
    "    return str(selected_event)\n",
    "\n",
    "\n",
    "def _format_price(price):\n",
    "    if price in (None, \"\"):\n",
    "        return \"\"\n",
    "    if isinstance(price, (int, float)):\n",
    "        return f\"{int(price):,} KRW\"\n",
    "    text = str(price).strip()\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    if text.replace(\",\", \"\").isdigit():\n",
    "        return f\"{int(text.replace(',', '')):,} KRW\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def _format_persona(persona_profile):\n",
    "    if not isinstance(persona_profile, dict):\n",
    "        return str(persona_profile or \"\")\n",
    "    name = persona_profile.get(\"name\", \"\")\n",
    "    extras = []\n",
    "    value_focus = persona_profile.get(\"value_focus\")\n",
    "    skin_type = persona_profile.get(\"skin_type\")\n",
    "    traits = persona_profile.get(\"traits\")\n",
    "    shopping_style = persona_profile.get(\"shopping_style\")\n",
    "    if value_focus:\n",
    "        extras.append(str(value_focus))\n",
    "    if skin_type:\n",
    "        extras.append(str(skin_type))\n",
    "    if traits:\n",
    "        if isinstance(traits, list):\n",
    "            extras.append(\", \".join([str(t) for t in traits if t]))\n",
    "        else:\n",
    "            extras.append(str(traits))\n",
    "    if shopping_style:\n",
    "        extras.append(str(shopping_style))\n",
    "    extra_text = \", \".join([e for e in extras if e])\n",
    "    if name and extra_text:\n",
    "        return f\"{name} ({extra_text})\"\n",
    "    return name or extra_text\n",
    "\n",
    "\n",
    "def _build_context_block(out, max_style_templates=3):\n",
    "    persona = _format_persona(out.get(\"persona_profile\"))\n",
    "    stage = out.get(\"stage_name\") or out.get(\"stage_kr\") or \"\"\n",
    "    brand = out.get(\"brand\") or \"\"\n",
    "    product_basic = out.get(\"product_basic\") if isinstance(out.get(\"product_basic\"), dict) else {}\n",
    "    product_name = product_basic.get(\"name\") or out.get(\"product_query\") or \"\"\n",
    "    price = _format_price(product_basic.get(\"price\"))\n",
    "    objective = out.get(\"objective\") or \"\"\n",
    "    target_state = out.get(\"target_state\") or \"\"\n",
    "    style_templates = out.get(\"style_templates\") or []\n",
    "    if isinstance(style_templates, list):\n",
    "        style_templates = style_templates[:max_style_templates]\n",
    "    selected_event = _format_event(out.get(\"selected_event\"))\n",
    "\n",
    "    lines = [\"[Context]\"]\n",
    "    if persona:\n",
    "        lines.append(f\"- Persona: {persona}\")\n",
    "    if stage:\n",
    "        lines.append(f\"- Stage: {stage}\")\n",
    "    if brand or product_name:\n",
    "        lines.append(f\"- Brand/Product: {brand} / {product_name}\".strip())\n",
    "    if price:\n",
    "        lines.append(f\"- Price: {price}\")\n",
    "    if objective:\n",
    "        lines.append(f\"- Objective: {objective}\")\n",
    "    if target_state:\n",
    "        lines.append(f\"- Target state: {target_state}\")\n",
    "    if style_templates:\n",
    "        lines.append(\"- Style templates:\")\n",
    "        for item in style_templates:\n",
    "            lines.append(f\"  - {item}\")\n",
    "    lines.append(f\"- Event: {selected_event}\")\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "def _extract_message(out):\n",
    "    exaone = out.get(\"exaone\", {}) if isinstance(out, dict) else {}\n",
    "    return exaone.get(\"result_raw\") or \"\"\n",
    "\n",
    "\n",
    "def _tokenize(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    return [t for t in re.split(r\"\\s+\", str(text)) if len(t) > 1]\n",
    "\n",
    "\n",
    "def _split_tokens(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    cleaned = re.sub(r\"[^\\w\\uac00-\\ud7a3]+\", \" \", str(text), flags=re.UNICODE)\n",
    "    return [t for t in cleaned.split() if len(t) > 1]\n",
    "\n",
    "\n",
    "def _extract_keywords(texts, max_terms=30):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        for token in _split_tokens(text):\n",
    "            if token.isdigit():\n",
    "                continue\n",
    "            counter[token] += 1\n",
    "    if not counter:\n",
    "        return []\n",
    "    return [item for item, _ in counter.most_common(max_terms)]\n",
    "\n",
    "\n",
    "def _coverage_score(message, out):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    if not message:\n",
    "        return 0.0\n",
    "\n",
    "    brand = out.get(\"brand\")\n",
    "    if brand:\n",
    "        total += 1\n",
    "        if brand in message:\n",
    "            hits += 1\n",
    "\n",
    "    product_basic = out.get(\"product_basic\") if isinstance(out.get(\"product_basic\"), dict) else {}\n",
    "    product_name = product_basic.get(\"name\") or out.get(\"product_query\") or \"\"\n",
    "    if product_name:\n",
    "        total += 1\n",
    "        if product_name in message:\n",
    "            hits += 1\n",
    "\n",
    "    selected_event = _format_event(out.get(\"selected_event\"))\n",
    "    if selected_event and selected_event != \"none\":\n",
    "        total += 1\n",
    "        if selected_event in message:\n",
    "            hits += 1\n",
    "\n",
    "    stage_terms = []\n",
    "    for text in (out.get(\"stage_kr\"), out.get(\"objective\"), out.get(\"target_state\")):\n",
    "        stage_terms.extend(_tokenize(text))\n",
    "    if stage_terms:\n",
    "        total += 1\n",
    "        if any(term in message for term in stage_terms):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / total if total else 0.0\n",
    "\n",
    "\n",
    "def _tone_match_score(message, brand_story):\n",
    "    if not message or not isinstance(brand_story, dict):\n",
    "        return 0.0\n",
    "    tone_keywords = brand_story.get(\"tone_keywords\") or []\n",
    "    if not tone_keywords:\n",
    "        return 0.0\n",
    "    hits = sum(1 for kw in tone_keywords if kw and kw in message)\n",
    "    return hits / len(tone_keywords)\n",
    "\n",
    "\n",
    "def _style_match_score(message, style_templates, max_terms=30):\n",
    "    if not message or not style_templates:\n",
    "        return 0.0\n",
    "    if not isinstance(style_templates, list):\n",
    "        style_templates = [str(style_templates)]\n",
    "    keywords = _extract_keywords(style_templates, max_terms=max_terms)\n",
    "    if not keywords:\n",
    "        return 0.0\n",
    "    hits = sum(1 for kw in keywords if kw in message)\n",
    "    return hits / len(keywords)\n",
    "\n",
    "\n",
    "def _info_density(message, out):\n",
    "    if not message:\n",
    "        return 0.0\n",
    "    persona = out.get(\"persona_profile\") if isinstance(out.get(\"persona_profile\"), dict) else {}\n",
    "    product_basic = out.get(\"product_basic\") if isinstance(out.get(\"product_basic\"), dict) else {}\n",
    "    context_texts = [\n",
    "        out.get(\"brand\"),\n",
    "        product_basic.get(\"name\"),\n",
    "        out.get(\"product_query\"),\n",
    "        out.get(\"stage_kr\"),\n",
    "        out.get(\"objective\"),\n",
    "        out.get(\"target_state\"),\n",
    "        persona.get(\"value_focus\"),\n",
    "        persona.get(\"skin_type\"),\n",
    "    ]\n",
    "    if isinstance(persona.get(\"traits\"), list):\n",
    "        context_texts.extend(persona.get(\"traits\"))\n",
    "    if persona.get(\"shopping_style\"):\n",
    "        context_texts.append(persona.get(\"shopping_style\"))\n",
    "\n",
    "    keywords = _extract_keywords([t for t in context_texts if t], max_terms=40)\n",
    "    if not keywords:\n",
    "        return 0.0\n",
    "    message_tokens = _split_tokens(message)\n",
    "    if not message_tokens:\n",
    "        return 0.0\n",
    "    hits = sum(1 for kw in keywords if kw in message)\n",
    "    return hits / len(message_tokens)\n",
    "\n",
    "\n",
    "def _repetition_stats(message):\n",
    "    tokens = _split_tokens(message)\n",
    "    if not tokens:\n",
    "        return 0.0, 0.0\n",
    "    unique_tokens = set(tokens)\n",
    "    repeat_token_ratio = (len(tokens) - len(unique_tokens)) / len(tokens)\n",
    "\n",
    "    if len(tokens) < 6:\n",
    "        return repeat_token_ratio, 0.0\n",
    "    n = 3\n",
    "    ngrams = [\" \".join(tokens[i:i + n]) for i in range(len(tokens) - n + 1)]\n",
    "    counts = Counter(ngrams)\n",
    "    total_ngrams = len(ngrams)\n",
    "    repeated = sum(count - 1 for count in counts.values() if count > 1)\n",
    "    repeat_ngram_ratio = repeated / total_ngrams if total_ngrams else 0.0\n",
    "    return repeat_token_ratio, repeat_ngram_ratio\n",
    "\n",
    "\n",
    "def _length_target(stage_name):\n",
    "    if stage_name == \"Acquisition\":\n",
    "        return 60, 200\n",
    "    if stage_name == \"Activation\":\n",
    "        return 60, 200\n",
    "    if stage_name == \"Retention\":\n",
    "        return 60, 180\n",
    "    if stage_name == \"Revenue\":\n",
    "        return 60, 180\n",
    "    if stage_name == \"Referral\":\n",
    "        return 60, 160\n",
    "    return 50, 220\n",
    "\n",
    "\n",
    "def _length_ok(message, stage_name):\n",
    "    if not message:\n",
    "        return False\n",
    "    min_len, max_len = _length_target(stage_name)\n",
    "    return min_len <= len(message) <= max_len\n",
    "\n",
    "\n",
    "def _forbidden_violations(message, crm_goal):\n",
    "    if not message or not isinstance(crm_goal, dict):\n",
    "        return 0\n",
    "    forbidden = crm_goal.get(\"forbidden_context\") or []\n",
    "    if not forbidden:\n",
    "        return 0\n",
    "    hits = 0\n",
    "    for term in forbidden:\n",
    "        if term and term in message:\n",
    "            hits += 1\n",
    "    return hits\n",
    "\n",
    "\n",
    "def _cta_present(message):\n",
    "    if not message:\n",
    "        return False\n",
    "    cta_markers = [\n",
    "        \"\\uc9c0\\uae08\", \"\\ud655\\uc778\", \"\\uad6c\\ub9e4\", \"\\uc2e0\\uccad\", \"\\ucc38\\uc5ec\",\n",
    "        \"\\ud074\\ub9ad\", \"\\ubc1b\\uae30\", \"\\ud61c\\ud0dd\", \"\\ud560\\uc778\", \"\\ucfe0\\ud3f0\",\n",
    "        \"\\ud574\\ubcf4\\uc138\\uc694\", \"\\ud558\\uc138\\uc694\", \"\\ub458\\ub7ec\\ubcf4\\uae30\",\n",
    "        \"\\ubc14\\ub85c\", \"\\ucd94\\ucc9c\", \"\\ubb38\\uc758\"\n",
    "    ]\n",
    "    return any(marker in message for marker in cta_markers)\n",
    "\n",
    "\n",
    "def _call_gpt(context_block, base_message, adapter_message):\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY is not set.\")\n",
    "\n",
    "    candidate_block = (\n",
    "        \"[0]\\n\"\n",
    "        f\"{base_message}\\n\\n\"\n",
    "        \"[1]\\n\"\n",
    "        f\"{adapter_message}\"\n",
    "    )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are evaluating CRM messages. Pick the message more likely to drive conversion.\\n\"\n",
    "        \"Compare with these criteria:\\n\"\n",
    "        \"1) Likelihood of action (click/repurchase)\\n\"\n",
    "        \"2) Fit to persona and stage goals\\n\"\n",
    "        \"3) Brand/product value delivery\\n\"\n",
    "        \"4) Use of style templates and event context when applicable\\n\"\n",
    "        \"5) Clarity without unnecessary decoration\\n\"\n",
    "        \"Return only the best candidate index as an integer (0 or 1).\"\n",
    "    )\n",
    "    user_prompt = (\n",
    "        \"Context:\\n\"\n",
    "        f\"{context_block}\\n\\n\"\n",
    "        \"Candidates:\\n\"\n",
    "        f\"{candidate_block}\\n\\n\"\n",
    "        \"Return only the best candidate index.\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-5-nano\",\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": system_prompt}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": user_prompt}],\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        \"https://api.openai.com/v1/responses\",\n",
    "        data=json.dumps(payload).encode(\"utf-8\"),\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        method=\"POST\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(request, timeout=30) as response:\n",
    "            data = json.loads(response.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as exc:\n",
    "        body = exc.read().decode(\"utf-8\", errors=\"replace\")\n",
    "        raise RuntimeError(f\"OpenAI API error {exc.code}: {body}\") from exc\n",
    "\n",
    "    output_text = data.get(\"output_text\", \"\")\n",
    "    match = re.search(r\"-?\\d+\", str(output_text))\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid evaluator response: {output_text}\")\n",
    "    choice = int(match.group(0))\n",
    "    if choice not in (0, 1):\n",
    "        raise ValueError(f\"Evaluator index out of range: {choice}\")\n",
    "    return choice\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def _patch_exaone(pipeline_module, adapter_path=None):\n",
    "    import tone_correction\n",
    "\n",
    "    class PatchedExaoneToneCorrector(tone_correction.ExaoneToneCorrector):\n",
    "        _cache = {}\n",
    "\n",
    "        def __init__(self, model_name=\"LGAI-EXAONE/EXAONE-4.0-1.2B\"):\n",
    "            key = (model_name, adapter_path)\n",
    "            cached = self._cache.get(key)\n",
    "            if cached:\n",
    "                self.device = cached[\"device\"]\n",
    "                self.model_name = model_name\n",
    "                self.tokenizer = cached[\"tokenizer\"]\n",
    "                self.model = cached[\"model\"]\n",
    "                return\n",
    "            super().__init__(model_name=model_name)\n",
    "            if adapter_path:\n",
    "                try:\n",
    "                    from peft import PeftModel\n",
    "                except ImportError as exc:\n",
    "                    raise RuntimeError(\"peft is required to load adapters.\") from exc\n",
    "                self.model = PeftModel.from_pretrained(self.model, adapter_path)\n",
    "                try:\n",
    "                    self.model.eval()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            self._cache[key] = {\n",
    "                \"device\": self.device,\n",
    "                \"tokenizer\": self.tokenizer,\n",
    "                \"model\": self.model,\n",
    "            }\n",
    "\n",
    "    original = pipeline_module.ExaoneToneCorrector\n",
    "    pipeline_module.ExaoneToneCorrector = PatchedExaoneToneCorrector\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        pipeline_module.ExaoneToneCorrector = original\n",
    "\n",
    "\n",
    "def _run_pipeline_main(pipeline_main, row):\n",
    "    argv = [\n",
    "        \"run_qwen_exaone_pipeline.py\",\n",
    "        \"--persona\",\n",
    "        str(row[\"persona\"]),\n",
    "        \"--brand\",\n",
    "        row[\"brand\"],\n",
    "        \"--product\",\n",
    "        row[\"product\"],\n",
    "        \"--stage_index\",\n",
    "        str(row[\"stage_index\"]),\n",
    "        \"--style_index\",\n",
    "        str(row[\"style_index\"]),\n",
    "        \"--is_event\",\n",
    "        \"1\" if row.get(\"is_event\", False) else \"0\",\n",
    "    ]\n",
    "    old_argv = sys.argv\n",
    "    try:\n",
    "        sys.argv = argv\n",
    "        return pipeline_main()\n",
    "    finally:\n",
    "        sys.argv = old_argv\n",
    "\n",
    "\n",
    "def _write_report(out_path, summary, rows, max_examples):\n",
    "    lines = []\n",
    "    lines.append(\"# Adapter Comparison Report\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"- CSV: {summary['csv']}\")\n",
    "    lines.append(f\"- Adapter: {summary['adapter']}\")\n",
    "    lines.append(f\"- Samples: {summary['samples']}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Summary\")\n",
    "    lines.append(\"\")\n",
    "    for item in summary[\"metrics\"]:\n",
    "        lines.append(f\"- {item}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Per-sample Results\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\n",
    "        \"| idx | persona | brand/product | stage | event | gpt winner | base len | adapter len | base cov | adapter cov | base tone | adapter tone | base style | adapter style | base dens | adapter dens | base rep tok | adapter rep tok | base rep 3g | adapter rep 3g | base len ok | adapter len ok | base forb | adapter forb | base cta | adapter cta |\"\n",
    "    )\n",
    "    lines.append(\n",
    "        \"| --- | --- | --- | --- | --- | --- | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --- | --- | ---: | ---: | --- | --- |\"\n",
    "    )\n",
    "    for item in rows:\n",
    "        lines.append(\n",
    "            \"| {idx} | {persona} | {brand_product} | {stage} | {event} | {winner} | {base_len} | {adapter_len} | {base_cov:.2f} | {adapter_cov:.2f} | {base_tone:.2f} | {adapter_tone:.2f} | {base_style:.2f} | {adapter_style:.2f} | {base_density:.2f} | {adapter_density:.2f} | {base_rep_token:.2f} | {adapter_rep_token:.2f} | {base_rep_ngram:.2f} | {adapter_rep_ngram:.2f} | {base_len_ok} | {adapter_len_ok} | {base_forbidden} | {adapter_forbidden} | {base_cta} | {adapter_cta} |\".format(\n",
    "                idx=item[\"idx\"],\n",
    "                persona=item[\"persona\"],\n",
    "                brand_product=item[\"brand_product\"],\n",
    "                stage=item[\"stage\"],\n",
    "                event=item[\"event\"],\n",
    "                winner=item[\"winner\"],\n",
    "                base_len=item[\"base_len\"],\n",
    "                adapter_len=item[\"adapter_len\"],\n",
    "                base_cov=item[\"base_cov\"],\n",
    "                adapter_cov=item[\"adapter_cov\"],\n",
    "                base_tone=item[\"base_tone\"],\n",
    "                adapter_tone=item[\"adapter_tone\"],\n",
    "                base_style=item[\"base_style\"],\n",
    "                adapter_style=item[\"adapter_style\"],\n",
    "                base_density=item[\"base_density\"],\n",
    "                adapter_density=item[\"adapter_density\"],\n",
    "                base_rep_token=item[\"base_rep_token\"],\n",
    "                adapter_rep_token=item[\"adapter_rep_token\"],\n",
    "                base_rep_ngram=item[\"base_rep_ngram\"],\n",
    "                adapter_rep_ngram=item[\"adapter_rep_ngram\"],\n",
    "                base_len_ok=\"yes\" if item[\"base_len_ok\"] else \"no\",\n",
    "                adapter_len_ok=\"yes\" if item[\"adapter_len_ok\"] else \"no\",\n",
    "                base_forbidden=item[\"base_forbidden\"],\n",
    "                adapter_forbidden=item[\"adapter_forbidden\"],\n",
    "                base_cta=\"yes\" if item[\"base_cta\"] else \"no\",\n",
    "                adapter_cta=\"yes\" if item[\"adapter_cta\"] else \"no\",\n",
    "            )\n",
    "        )\n",
    "    lines.append(\"\")\n",
    "\n",
    "    if max_examples > 0:\n",
    "        lines.append(\"## Examples\")\n",
    "        lines.append(\"\")\n",
    "        for item in rows[:max_examples]:\n",
    "            lines.append(f\"### Sample {item['idx']}\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"Context:\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"```\")\n",
    "            lines.append(item[\"context\"])\n",
    "            lines.append(\"```\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"Base message:\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"```\")\n",
    "            lines.append(item[\"base_message\"])\n",
    "            lines.append(\"```\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"Adapter message:\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"```\")\n",
    "            lines.append(item[\"adapter_message\"])\n",
    "            lines.append(\"```\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(f\"GPT winner: {item['winner']}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--csv_path\", default=DEFAULT_CSV)\n",
    "    parser.add_argument(\"--adapter_path\", default=DEFAULT_ADAPTER_DIR)\n",
    "    parser.add_argument(\"--out_path\", default=None)\n",
    "    parser.add_argument(\"--max_rows\", type=int, default=None)\n",
    "    parser.add_argument(\"--max_examples\", type=int, default=3)\n",
    "    parser.add_argument(\"--skip_llm_eval\", action=\"store_true\")\n",
    "    parser.add_argument(\"--max_style_templates\", type=int, default=3)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not os.path.exists(args.csv_path):\n",
    "        raise FileNotFoundError(f\"CSV not found: {args.csv_path}\")\n",
    "    if not os.path.exists(args.adapter_path):\n",
    "        raise FileNotFoundError(f\"Adapter not found: {args.adapter_path}\")\n",
    "\n",
    "    pipeline_module = _import_pipeline_module()\n",
    "    pipeline_main = pipeline_module.main\n",
    "    brand_stories = _load_json(os.path.join(PROJECT_DIR, \"data\", \"brand_stories.json\"))\n",
    "    crm_goals = _load_json(os.path.join(PROJECT_DIR, \"data\", \"crm_goals.json\"))\n",
    "\n",
    "    rows = []\n",
    "    for idx, row in enumerate(_load_rows(args.csv_path)):\n",
    "        if args.max_rows is not None and idx >= args.max_rows:\n",
    "            break\n",
    "        rows.append(row)\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No rows to evaluate.\")\n",
    "\n",
    "    results = []\n",
    "    wins = {\"base\": 0, \"adapter\": 0}\n",
    "\n",
    "    for idx, row in enumerate(rows, start=1):\n",
    "        _log(\n",
    "            \"[Row {idx}] persona={persona} brand={brand} product={product} \"\n",
    "            \"stage_index={stage_index} style_index={style_index} is_event={is_event}\".format(\n",
    "                idx=idx,\n",
    "                persona=row[\"persona\"],\n",
    "                brand=row[\"brand\"],\n",
    "                product=row[\"product\"],\n",
    "                stage_index=row[\"stage_index\"],\n",
    "                style_index=row[\"style_index\"],\n",
    "                is_event=row.get(\"is_event\", False),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        _log(\"  Running base pipeline...\")\n",
    "        base_out = _run_pipeline_main(pipeline_main, row)\n",
    "\n",
    "        _log(\"  Running adapter pipeline...\")\n",
    "        with _patch_exaone(pipeline_module, adapter_path=args.adapter_path):\n",
    "            adapter_out = _run_pipeline_main(pipeline_main, row)\n",
    "\n",
    "        base_message = _extract_message(base_out)\n",
    "        adapter_message = _extract_message(adapter_out)\n",
    "\n",
    "        context_block = _build_context_block(base_out, args.max_style_templates)\n",
    "        stage_name = base_out.get(\"stage_name\") or _get_stage_name(row[\"stage_index\"])\n",
    "        crm_goal = _get_crm_goal(crm_goals, row[\"stage_index\"], stage_name)\n",
    "        brand_story = _get_brand_story(brand_stories, base_out.get(\"brand\"))\n",
    "\n",
    "        winner = \"n/a\"\n",
    "        if not args.skip_llm_eval:\n",
    "            choice = _call_gpt(context_block, base_message, adapter_message)\n",
    "            winner = \"base\" if choice == 0 else \"adapter\"\n",
    "            wins[winner] += 1\n",
    "\n",
    "        base_cov = _coverage_score(base_message, base_out)\n",
    "        adapter_cov = _coverage_score(adapter_message, base_out)\n",
    "        base_tone = _tone_match_score(base_message, brand_story)\n",
    "        adapter_tone = _tone_match_score(adapter_message, brand_story)\n",
    "        base_style = _style_match_score(base_message, base_out.get(\"style_templates\"))\n",
    "        adapter_style = _style_match_score(adapter_message, base_out.get(\"style_templates\"))\n",
    "        base_density = _info_density(base_message, base_out)\n",
    "        adapter_density = _info_density(adapter_message, base_out)\n",
    "        base_rep_token, base_rep_ngram = _repetition_stats(base_message)\n",
    "        adapter_rep_token, adapter_rep_ngram = _repetition_stats(adapter_message)\n",
    "        base_len_ok = _length_ok(base_message, stage_name)\n",
    "        adapter_len_ok = _length_ok(adapter_message, stage_name)\n",
    "        base_forbidden = _forbidden_violations(base_message, crm_goal)\n",
    "        adapter_forbidden = _forbidden_violations(adapter_message, crm_goal)\n",
    "        base_len = len(base_message)\n",
    "        adapter_len = len(adapter_message)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"idx\": idx,\n",
    "                \"persona\": row[\"persona\"],\n",
    "                \"brand_product\": f\"{row['brand']} / {row['product']}\",\n",
    "                \"stage\": base_out.get(\"stage_name\") or base_out.get(\"stage_kr\") or \"\",\n",
    "                \"event\": _format_event(base_out.get(\"selected_event\")),\n",
    "                \"winner\": winner,\n",
    "                \"base_len\": base_len,\n",
    "                \"adapter_len\": adapter_len,\n",
    "                \"base_cov\": base_cov,\n",
    "                \"adapter_cov\": adapter_cov,\n",
    "                \"base_tone\": base_tone,\n",
    "                \"adapter_tone\": adapter_tone,\n",
    "                \"base_style\": base_style,\n",
    "                \"adapter_style\": adapter_style,\n",
    "                \"base_density\": base_density,\n",
    "                \"adapter_density\": adapter_density,\n",
    "                \"base_rep_token\": base_rep_token,\n",
    "                \"adapter_rep_token\": adapter_rep_token,\n",
    "                \"base_rep_ngram\": base_rep_ngram,\n",
    "                \"adapter_rep_ngram\": adapter_rep_ngram,\n",
    "                \"base_len_ok\": base_len_ok,\n",
    "                \"adapter_len_ok\": adapter_len_ok,\n",
    "                \"base_forbidden\": base_forbidden,\n",
    "                \"adapter_forbidden\": adapter_forbidden,\n",
    "                \"base_cta\": _cta_present(base_message),\n",
    "                \"adapter_cta\": _cta_present(adapter_message),\n",
    "                \"context\": context_block,\n",
    "                \"base_message\": base_message,\n",
    "                \"adapter_message\": adapter_message,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    avg_base_cov = sum(r[\"base_cov\"] for r in results) / len(results)\n",
    "    avg_adapter_cov = sum(r[\"adapter_cov\"] for r in results) / len(results)\n",
    "    avg_base_tone = sum(r[\"base_tone\"] for r in results) / len(results)\n",
    "    avg_adapter_tone = sum(r[\"adapter_tone\"] for r in results) / len(results)\n",
    "    avg_base_style = sum(r[\"base_style\"] for r in results) / len(results)\n",
    "    avg_adapter_style = sum(r[\"adapter_style\"] for r in results) / len(results)\n",
    "    avg_base_density = sum(r[\"base_density\"] for r in results) / len(results)\n",
    "    avg_adapter_density = sum(r[\"adapter_density\"] for r in results) / len(results)\n",
    "    avg_base_rep_token = sum(r[\"base_rep_token\"] for r in results) / len(results)\n",
    "    avg_adapter_rep_token = sum(r[\"adapter_rep_token\"] for r in results) / len(results)\n",
    "    avg_base_rep_ngram = sum(r[\"base_rep_ngram\"] for r in results) / len(results)\n",
    "    avg_adapter_rep_ngram = sum(r[\"adapter_rep_ngram\"] for r in results) / len(results)\n",
    "    base_len_ok_rate = sum(1 for r in results if r[\"base_len_ok\"]) / len(results)\n",
    "    adapter_len_ok_rate = sum(1 for r in results if r[\"adapter_len_ok\"]) / len(results)\n",
    "    base_forbidden_rate = sum(1 for r in results if r[\"base_forbidden\"] > 0) / len(results)\n",
    "    adapter_forbidden_rate = sum(1 for r in results if r[\"adapter_forbidden\"] > 0) / len(results)\n",
    "    base_cta_rate = sum(1 for r in results if r[\"base_cta\"]) / len(results)\n",
    "    adapter_cta_rate = sum(1 for r in results if r[\"adapter_cta\"]) / len(results)\n",
    "    avg_base_len = sum(r[\"base_len\"] for r in results) / len(results)\n",
    "    avg_adapter_len = sum(r[\"adapter_len\"] for r in results) / len(results)\n",
    "\n",
    "    timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "    out_path = args.out_path or os.path.join(\n",
    "        BASE_DIR, f\"adapter_comparison_{timestamp}.md\"\n",
    "    )\n",
    "\n",
    "    summary = {\n",
    "        \"csv\": args.csv_path,\n",
    "        \"adapter\": args.adapter_path,\n",
    "        \"samples\": len(results),\n",
    "        \"metrics\": [\n",
    "            f\"GPT wins: adapter {wins['adapter']} / base {wins['base']} (skip_llm_eval={args.skip_llm_eval})\",\n",
    "            f\"Avg coverage: adapter {avg_adapter_cov:.2f}, base {avg_base_cov:.2f}\",\n",
    "            f\"Avg tone match: adapter {avg_adapter_tone:.2f}, base {avg_base_tone:.2f}\",\n",
    "            f\"Avg style match: adapter {avg_adapter_style:.2f}, base {avg_base_style:.2f}\",\n",
    "            f\"Avg info density: adapter {avg_adapter_density:.2f}, base {avg_base_density:.2f}\",\n",
    "            f\"Repeat token ratio: adapter {avg_adapter_rep_token:.2f}, base {avg_base_rep_token:.2f}\",\n",
    "            f\"Repeat 3-gram ratio: adapter {avg_adapter_rep_ngram:.2f}, base {avg_base_rep_ngram:.2f}\",\n",
    "            f\"Length ok rate: adapter {adapter_len_ok_rate:.2f}, base {base_len_ok_rate:.2f}\",\n",
    "            f\"Forbidden violation rate: adapter {adapter_forbidden_rate:.2f}, base {base_forbidden_rate:.2f}\",\n",
    "            f\"CTA rate: adapter {adapter_cta_rate:.2f}, base {base_cta_rate:.2f}\",\n",
    "            f\"Avg length: adapter {avg_adapter_len:.1f}, base {avg_base_len:.1f}\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    _write_report(out_path, summary, results, args.max_examples)\n",
    "    _log(f\"Saved report: {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
