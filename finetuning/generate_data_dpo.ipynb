{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "코랩용 DPO (Direct Preference Optimization) DataSet 생성 스크립트\n",
        "./random_persona_campaign.csv 파일을 토대로 각 입력 데이터에 맞는 CRM 예시를 생성해\n",
        "/content/drive/MyDrive/멋사/dpo_dataset/에 저장\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "zcoml2-WZect",
        "outputId": "e6b06142-f642-40e4-871d-ecd79905110d"
      },
      "id": "zcoml2-WZect",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n코랩용 DPO (Direct Preference Optimization) DataSet 생성 스크립트\\n./random_persona_campaign.csv 파일을 토대로 각 입력 데이터에 맞는 CRM 예시를 생성해\\n/content/drive/MyDrive/멋사/dpo_dataset/에 저장\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "print(os.getcwd())\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VqfSF4maCuw",
        "outputId": "e050e6f6-af0f-4f4f-f9e2-dda3788d3261"
      },
      "id": "2VqfSF4maCuw",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "['.config', 'drive', '.ipynb_checkpoints', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets peft trl bitsandbytes accelerate\n",
        "!pip install -U transformers\n",
        "!pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htxfJa9laf62",
        "outputId": "7052577e-f5f6-43a0-81a6-83c8dc527177"
      },
      "id": "htxfJa9laf62",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.57.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.7.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.22.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Downloading trl-0.26.2-py3-none-any.whl (518 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, trl\n",
            "Successfully installed bitsandbytes-0.49.0 trl-0.26.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Name: transformers\n",
            "Version: 4.57.3\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers, trl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jjjh02/AmoRe_crm_generator.git\n",
        "%cd AmoRe_crm_generator\n",
        "!git checkout jinhyeok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QVJ97GpaTBP",
        "outputId": "e4de5a76-3a9b-4e8c-a9f4-71ae7fba83d0"
      },
      "id": "_QVJ97GpaTBP",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AmoRe_crm_generator'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 108 (delta 46), reused 83 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (108/108), 1.86 MiB | 12.30 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "/content/AmoRe_crm_generator\n",
            "Branch 'jinhyeok' set up to track remote branch 'jinhyeok' from 'origin'.\n",
            "Switched to a new branch 'jinhyeok'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch\n",
        "os.chdir(\"/content/AmoRe_crm_generator/finetuning\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874ZkCWcblne",
        "outputId": "537a40e0-3e93-45f6-d7c0-84416188f2c8"
      },
      "id": "874ZkCWcblne",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mjinhyeok\u001b[m\n",
            "  main\u001b[m\n",
            "/content/AmoRe_crm_generator/finetuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "Y5imCzsdtN_b",
        "outputId": "ae6399a0-8f87-4d48-ea2b-7376ac2452f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Y5imCzsdtN_b",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0235b99f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0235b99f",
        "outputId": "7f900a45-f648-4a53-edb7-0032d023506a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded existing records: 0\n",
            "Resuming from CSV row index: 0\n",
            "CSV: /content/AmoRe_crm_generator/finetuning/random_persona_campaign.csv\n",
            "Output: /content/AmoRe_crm_generator/finetuning/finetuning_data_dpo/cycle_01.json\n",
            "Candidates per row: 4\n",
            "Loaded existing records: 0\n",
            "[Row 0] persona=2 brand=에뛰드 product=뽀오얀 미소 발효 립&아이 리무버 250ml (대용량) stage_index=4 style_index=0 is_event=False\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 0] Raw candidates: 4\n",
            "[Row 0] Deduped candidates: 4\n",
            "[Row 0] Best candidate index: 2\n",
            "[Row 1] persona=2 brand=아이오페 product=수분가득 콜라겐 크림 75ml stage_index=4 style_index=2 is_event=False\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 1] Raw candidates: 4\n",
            "[Row 1] Deduped candidates: 4\n",
            "[Row 1] Evaluator error: The read operation timed out\n",
            "[Row 2] persona=2 brand=코스알엑스 product=더 나이아신아마이드 15 세럼 20ml stage_index=0 style_index=5 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 2] Raw candidates: 4\n",
            "[Row 2] Deduped candidates: 4\n",
            "[Row 2] Best candidate index: 2\n",
            "[Row 3] persona=1 brand=에스트라 product=아토베리어 365 하이드로 수딩크림 60ml stage_index=2 style_index=2 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 3] Raw candidates: 4\n",
            "[Row 3] Deduped candidates: 4\n",
            "[Row 3] Best candidate index: 2\n",
            "[Row 4] persona=2 brand=이니스프리 product=순정 디렉터 선크림 (톤업 수정/수분/무기자차) stage_index=1 style_index=1 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 4] Raw candidates: 4\n",
            "[Row 4] Deduped candidates: 4\n",
            "[Row 4] Best candidate index: 0\n",
            "[Checkpoint] Saved after 4 rows\n",
            "[Row 5] persona=0 brand=헤라 product=하이드로-듀 플럼핑 워터 드롭 50ml stage_index=4 style_index=5 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 5] Raw candidates: 4\n",
            "[Row 5] Deduped candidates: 4\n",
            "[Row 5] Evaluator error: The read operation timed out\n",
            "[Row 6] persona=0 brand=이니스프리 product=그린티 씨드 히알루론산 크림 50ml stage_index=1 style_index=2 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 6] Raw candidates: 4\n",
            "[Row 6] Deduped candidates: 4\n",
            "[Row 6] Best candidate index: 3\n",
            "[Row 7] persona=4 brand=코스알엑스 product=약산성 굿모닝 젤 클렌저 stage_index=1 style_index=4 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 7] Raw candidates: 4\n",
            "[Row 7] Deduped candidates: 4\n",
            "[Row 7] Best candidate index: 3\n",
            "[Row 8] persona=3 brand=설화수 product=NEW 레티놀 3X 리프팅 세럼 25ml stage_index=0 style_index=3 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 8] Raw candidates: 4\n",
            "[Row 8] Deduped candidates: 4\n",
            "[Row 8] Best candidate index: 3\n",
            "[Row 9] persona=4 brand=아이오페 product=NEW 비타티놀 바운시 리프트 세럼 30g 1입 stage_index=1 style_index=5 is_event=False\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 9] Raw candidates: 4\n",
            "[Row 9] Deduped candidates: 4\n",
            "[Row 9] Best candidate index: 1\n",
            "[Checkpoint] Saved after 8 rows\n",
            "[Row 10] persona=2 brand=기타 product=비타민C 엑스퍼트25% 토닝앰플 기획세트 23ml stage_index=4 style_index=2 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 10] Raw candidates: 4\n",
            "[Row 10] Deduped candidates: 4\n",
            "[Row 10] Best candidate index: 0\n",
            "[Row 11] persona=0 brand=일리윤 product=[3입] 히알루론 모이스춰 수분크림 stage_index=3 style_index=3 is_event=True\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n",
            "  [Attempt 4/4] Running pipeline\n",
            "  [Warn] Qwen draft differs across candidates; using the first one.\n",
            "[Row 11] Raw candidates: 4\n",
            "[Row 11] Deduped candidates: 4\n",
            "[Row 11] Best candidate index: 1\n",
            "[Row 12] persona=0 brand=한율 product=어린쑥 트러블 미스트 120ml stage_index=0 style_index=0 is_event=False\n",
            "  [Attempt 1/4] Running pipeline\n",
            "  [Attempt 2/4] Running pipeline\n",
            "  [Attempt 3/4] Running pipeline\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import csv\n",
        "import inspect\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import urllib.error\n",
        "import urllib.request\n",
        "from contextlib import redirect_stdout\n",
        "from io import StringIO\n",
        "\n",
        "\n",
        "BASE_DIR = os.getcwd()\n",
        "DEFAULT_CSV = os.path.join(BASE_DIR, \"random_persona_campaign.csv\")\n",
        "DEFAULT_OUTPUT = os.path.join(BASE_DIR, \"finetuning_data_dpo\", \"cycle_01.json\")\n",
        "SRC_DIR = os.path.abspath(os.path.join(BASE_DIR, \"..\", \"src\"))\n",
        "\n",
        "def _log(message):\n",
        "    print(message)\n",
        "\n",
        "\n",
        "def _import_pipeline_main():\n",
        "    if SRC_DIR not in sys.path:\n",
        "        sys.path.insert(0, SRC_DIR)\n",
        "    try:\n",
        "        from run_qwen_exaone_pipeline import main as pipeline_main\n",
        "    except Exception as exc:\n",
        "        raise ImportError(\n",
        "            \"Failed to import main from ../src/run_qwen_exaone_pipeline.py\"\n",
        "        ) from exc\n",
        "    return pipeline_main\n",
        "\n",
        "\n",
        "def _parse_bool(value):\n",
        "    if isinstance(value, bool):\n",
        "        return value\n",
        "    if value is None:\n",
        "        return False\n",
        "    if isinstance(value, (int, float)):\n",
        "        return bool(value)\n",
        "    text = str(value).strip().lower()\n",
        "    return text in {\"1\", \"true\", \"yes\", \"y\", \"t\"}\n",
        "\n",
        "\n",
        "def _load_pairs(csv_path):\n",
        "    with open(csv_path, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            if not row:\n",
        "                continue\n",
        "            persona_raw = row.get(\"persona\", \"\").strip()\n",
        "            brand_raw = row.get(\"brand\", \"\").strip()\n",
        "            product_raw = row.get(\"product\", \"\").strip()\n",
        "            stage_raw = row.get(\"stage_index\", \"\").strip()\n",
        "            style_raw = row.get(\"style_index\", \"\").strip()\n",
        "            if not persona_raw or not brand_raw or not product_raw:\n",
        "                continue\n",
        "            if not stage_raw or not style_raw:\n",
        "                continue\n",
        "            try:\n",
        "                persona = int(persona_raw)\n",
        "                stage_index = int(stage_raw)\n",
        "                style_index = int(style_raw)\n",
        "            except ValueError:\n",
        "                continue\n",
        "            yield {\n",
        "                \"persona\": persona,\n",
        "                \"brand\": brand_raw,\n",
        "                \"product\": product_raw,\n",
        "                \"stage_index\": stage_index,\n",
        "                \"style_index\": style_index,\n",
        "                \"is_event\": _parse_bool(row.get(\"is_event\", \"\")),\n",
        "            }\n",
        "\n",
        "\n",
        "def _format_prompt(summarization):\n",
        "    if summarization is None:\n",
        "        return \"\"\n",
        "    if isinstance(summarization, str):\n",
        "        return summarization.strip()\n",
        "    return json.dumps(summarization, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "def _format_event(selected_event):\n",
        "    if selected_event in (None, \"\", {}):\n",
        "        return \"없음\"\n",
        "    if isinstance(selected_event, dict):\n",
        "        for key in (\"title\", \"name\", \"event_name\", \"event\"):\n",
        "            if selected_event.get(key):\n",
        "                return str(selected_event.get(key))\n",
        "        return json.dumps(selected_event, ensure_ascii=False)\n",
        "    return str(selected_event)\n",
        "\n",
        "\n",
        "def _format_price(price):\n",
        "    if price in (None, \"\"):\n",
        "        return \"\"\n",
        "    if isinstance(price, (int, float)):\n",
        "        return f\"{int(price):,}원\"\n",
        "    text = str(price).strip()\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    if \"원\" in text:\n",
        "        return text\n",
        "    if text.replace(\",\", \"\").isdigit():\n",
        "        return f\"{int(text.replace(',', '')):,}원\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def _format_persona(persona_profile):\n",
        "    if not isinstance(persona_profile, dict):\n",
        "        return str(persona_profile or \"\")\n",
        "    name = persona_profile.get(\"name\", \"\")\n",
        "    extras = []\n",
        "    value_focus = persona_profile.get(\"value_focus\")\n",
        "    skin_type = persona_profile.get(\"skin_type\")\n",
        "    traits = persona_profile.get(\"traits\")\n",
        "    shopping_style = persona_profile.get(\"shopping_style\")\n",
        "    if value_focus:\n",
        "        extras.append(str(value_focus))\n",
        "    if skin_type:\n",
        "        extras.append(str(skin_type))\n",
        "    if traits:\n",
        "        if isinstance(traits, list):\n",
        "            extras.append(\", \".join([str(t) for t in traits if t]))\n",
        "        else:\n",
        "            extras.append(str(traits))\n",
        "    if shopping_style:\n",
        "        extras.append(str(shopping_style))\n",
        "    extra_text = \", \".join([e for e in extras if e])\n",
        "    if name and extra_text:\n",
        "        return f\"{name} ({extra_text})\"\n",
        "    return name or extra_text\n",
        "\n",
        "\n",
        "def _build_prompt_text(meta, fallback_text):\n",
        "    persona = _format_persona(meta.get(\"persona_profile\") if isinstance(meta, dict) else None)\n",
        "    stage = \"\"\n",
        "    if isinstance(meta, dict):\n",
        "        stage = meta.get(\"stage_name\") or meta.get(\"stage_kr\") or \"\"\n",
        "    brand = meta.get(\"brand\") if isinstance(meta, dict) else \"\"\n",
        "    product_basic = meta.get(\"product_basic\") if isinstance(meta, dict) else None\n",
        "    product_name = \"\"\n",
        "    price = \"\"\n",
        "    if isinstance(product_basic, dict):\n",
        "        product_name = product_basic.get(\"name\", \"\") or \"\"\n",
        "        price = _format_price(product_basic.get(\"price\"))\n",
        "    product_query = meta.get(\"product_query\") if isinstance(meta, dict) else \"\"\n",
        "    if not product_name:\n",
        "        product_name = product_query or \"\"\n",
        "\n",
        "    event_text = _format_event(meta.get(\"selected_event\") if isinstance(meta, dict) else None)\n",
        "\n",
        "    lines = [\"[컨텍스트]\"]\n",
        "    if persona:\n",
        "        lines.append(f\"- Persona: {persona}\")\n",
        "    if stage:\n",
        "        lines.append(f\"- Stage: {stage}\")\n",
        "    if brand or product_name:\n",
        "        lines.append(f\"- Brand/Product: {brand} / {product_name}\".strip())\n",
        "    if price:\n",
        "        lines.append(f\"- Price: {price}\")\n",
        "    lines.append(f\"- Event: {event_text}\")\n",
        "\n",
        "    prompt = \"\\n\".join(lines).strip()\n",
        "    if prompt:\n",
        "        return prompt\n",
        "    return _format_prompt(fallback_text)\n",
        "\n",
        "\n",
        "def _candidate_text(candidate):\n",
        "    if isinstance(candidate, dict):\n",
        "        return (\n",
        "            candidate.get(\"text\")\n",
        "            or candidate.get(\"crm_message\")\n",
        "            or candidate.get(\"message\")\n",
        "            or candidate.get(\"content\")\n",
        "        )\n",
        "    return str(candidate)\n",
        "\n",
        "\n",
        "def _candidate_meta(candidate):\n",
        "    if isinstance(candidate, dict):\n",
        "        return candidate.get(\"meta\") or {}\n",
        "    return {}\n",
        "\n",
        "\n",
        "def _normalize_candidates(raw):\n",
        "    if raw is None:\n",
        "        return []\n",
        "    if isinstance(raw, dict):\n",
        "        if \"candidates\" in raw:\n",
        "            raw = raw[\"candidates\"]\n",
        "        elif \"messages\" in raw:\n",
        "            raw = raw[\"messages\"]\n",
        "        elif \"crm_messages\" in raw:\n",
        "            raw = raw[\"crm_messages\"]\n",
        "        elif \"crm_message\" in raw and isinstance(raw[\"crm_message\"], list):\n",
        "            raw = raw[\"crm_message\"]\n",
        "        else:\n",
        "            raw = [raw]\n",
        "    if not isinstance(raw, list):\n",
        "        raw = [raw]\n",
        "\n",
        "    normalized = []\n",
        "    for idx, item in enumerate(raw):\n",
        "        text = _candidate_text(item)\n",
        "        if not text:\n",
        "            continue\n",
        "        normalized.append(\n",
        "            {\n",
        "                \"response_id\": idx,\n",
        "                \"text\": text,\n",
        "                \"meta\": _candidate_meta(item),\n",
        "            }\n",
        "        )\n",
        "    return normalized\n",
        "\n",
        "\n",
        "def _dedupe_candidates(items):\n",
        "    seen = set()\n",
        "    result = []\n",
        "    for item in items:\n",
        "        text = _candidate_text(item)\n",
        "        if not text:\n",
        "            continue\n",
        "        key = text.strip()\n",
        "        if not key or key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        result.append(item)\n",
        "    return result\n",
        "\n",
        "\n",
        "def _extract_response_text(data):\n",
        "    if isinstance(data, dict):\n",
        "        output_text = data.get(\"output_text\")\n",
        "        if isinstance(output_text, str) and output_text.strip():\n",
        "            return output_text.strip()\n",
        "\n",
        "        output = data.get(\"output\")\n",
        "        if isinstance(output, list):\n",
        "            parts = []\n",
        "            for item in output:\n",
        "                if not isinstance(item, dict):\n",
        "                    continue\n",
        "                content = item.get(\"content\", [])\n",
        "                if isinstance(content, list):\n",
        "                    for block in content:\n",
        "                        if isinstance(block, dict) and isinstance(block.get(\"text\"), str):\n",
        "                            parts.append(block[\"text\"])\n",
        "                        elif isinstance(block, str):\n",
        "                            parts.append(block)\n",
        "                elif isinstance(content, str):\n",
        "                    parts.append(content)\n",
        "            if parts:\n",
        "                return \"\".join(parts).strip()\n",
        "\n",
        "    raise ValueError(f\"Invalid evaluator response: {data}\")\n",
        "\n",
        "\n",
        "def _format_meta(meta):\n",
        "    if not isinstance(meta, dict):\n",
        "        return str(meta)\n",
        "\n",
        "    lines = []\n",
        "    persona_profile = meta.get(\"persona_profile\")\n",
        "    if persona_profile is not None:\n",
        "        lines.append(f\"persona_profile: {json.dumps(persona_profile, ensure_ascii=False)}\")\n",
        "    brand = meta.get(\"brand\")\n",
        "    if brand:\n",
        "        lines.append(f\"brand: {brand}\")\n",
        "    stage_kr = meta.get(\"stage_kr\")\n",
        "    if stage_kr:\n",
        "        lines.append(f\"stage_kr: {stage_kr}\")\n",
        "    objective = meta.get(\"objective\")\n",
        "    if objective:\n",
        "        lines.append(f\"objective: {objective}\")\n",
        "    target_state = meta.get(\"target_state\")\n",
        "    if target_state:\n",
        "        lines.append(f\"target_state: {target_state}\")\n",
        "    style_templates = meta.get(\"style_templates\")\n",
        "    if style_templates:\n",
        "        if isinstance(style_templates, list):\n",
        "            lines.append(\"style_templates:\")\n",
        "            for item in style_templates:\n",
        "                lines.append(f\"- {item}\")\n",
        "        else:\n",
        "            lines.append(f\"style_templates: {style_templates}\")\n",
        "    selected_event = meta.get(\"selected_event\")\n",
        "    if selected_event is not None:\n",
        "        if isinstance(selected_event, (dict, list)):\n",
        "            event_text = json.dumps(selected_event, ensure_ascii=False)\n",
        "        else:\n",
        "            event_text = str(selected_event)\n",
        "        lines.append(f\"selected_event: {event_text}\")\n",
        "\n",
        "    return \"\\n\".join(lines) if lines else \"(context unavailable)\"\n",
        "\n",
        "\n",
        "def _call_gpt(prompt_text, candidates):\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"OPENAI_API_KEY is not set.\")\n",
        "\n",
        "    candidate_lines = []\n",
        "    for idx, candidate in enumerate(candidates):\n",
        "        meta_block = _format_meta(candidate.get(\"meta\", {}))\n",
        "        candidate_lines.append(\n",
        "            f\"[{idx}]\\n\"\n",
        "            f\"crm_message:\\n{candidate.get('text', '')}\\n\\n\"\n",
        "            f\"context:\\n{meta_block}\"\n",
        "        )\n",
        "    candidate_block = \"\\n\\n\".join(candidate_lines)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"너는 CRM 메시지 평가자다.\\n\"\n",
        "        \"목표는 전환 가능성이 더 높은 메시지를 고르는 것이다.\\n\"\n",
        "        \"각 후보에는 메시지와 그 메시지에 사용된 컨텍스트가 함께 주어진다.\\n\\n\"\n",
        "        \"다음 기준으로 비교하라:\\n\"\n",
        "        \"1. 수신자가 실제 행동(클릭/재구매)을 할 가능성\\n\"\n",
        "        \"2. persona 및 stage_kr/objective/target_state 적합성\\n\"\n",
        "        \"3. 브랜드 핵심 장점 전달력\\n\"\n",
        "        \"4. style_templates 및 selected_event 반영 정도\\n\"\n",
        "        \"5. 불필요한 장식 없이 명확한가\\n\\n\"\n",
        "        \"더 나은 후보 하나를 선택하라.\"\n",
        "    )\n",
        "    user_prompt = (\n",
        "        \"컨텍스트:\\n\"\n",
        "        f\"{prompt_text}\\n\\n\"\n",
        "        \"후보:\\n\"\n",
        "        f\"{candidate_block}\\n\\n\"\n",
        "        \"더 나은 후보의 인덱스만 정수로 반환하라.\"\n",
        "    )\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"gpt-5-nano\",\n",
        "        \"input\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": [{\"type\": \"input_text\", \"text\": system_prompt}],\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [{\"type\": \"input_text\", \"text\": user_prompt}],\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    request = urllib.request.Request(\n",
        "        \"https://api.openai.com/v1/responses\",\n",
        "        data=json.dumps(payload).encode(\"utf-8\"),\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        },\n",
        "        method=\"POST\",\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        with urllib.request.urlopen(request, timeout=30) as response:\n",
        "            data = json.loads(response.read().decode(\"utf-8\"))\n",
        "    except urllib.error.HTTPError as exc:\n",
        "        body = exc.read().decode(\"utf-8\", errors=\"replace\")\n",
        "        raise RuntimeError(f\"OpenAI API error {exc.code}: {body}\") from exc\n",
        "\n",
        "    content = _extract_response_text(data)\n",
        "    match = re.search(r\"-?\\d+\", content)\n",
        "    if not match:\n",
        "        raise ValueError(f\"Invalid evaluator response: {content}\")\n",
        "    choice = int(match.group(0))\n",
        "    if choice < 0 or choice >= len(candidates):\n",
        "        raise ValueError(f\"Evaluator index out of range: {choice}\")\n",
        "    return choice\n",
        "\n",
        "\n",
        "def _load_existing_records(path):\n",
        "    if not os.path.exists(path):\n",
        "        return []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError(f\"Expected a list in {path}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def _save_records(path, records):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "def _extract_pipeline_output(result):\n",
        "    if isinstance(result, dict):\n",
        "        if \"qwen\" in result or \"exaone\" in result:\n",
        "            qwen = result.get(\"qwen\", {}) or {}\n",
        "            exaone = result.get(\"exaone\", {}) or {}\n",
        "            summarization = qwen.get(\"draft\") or qwen.get(\"qwen_draft\")\n",
        "            crm_message = exaone.get(\"result_raw\") or exaone.get(\"crm_message\")\n",
        "            meta = {\n",
        "                \"persona_profile\": result.get(\"persona_profile\"),\n",
        "                \"brand\": result.get(\"brand\"),\n",
        "                \"product_basic\": result.get(\"product_basic\"),\n",
        "                \"product_query\": result.get(\"product_query\"),\n",
        "                \"stage_name\": result.get(\"stage_name\"),\n",
        "                \"stage_kr\": result.get(\"stage_kr\"),\n",
        "                \"objective\": result.get(\"objective\"),\n",
        "                \"target_state\": result.get(\"target_state\"),\n",
        "                \"style_templates\": result.get(\"style_templates\"),\n",
        "                \"selected_event\": result.get(\"selected_event\"),\n",
        "            }\n",
        "            return summarization, crm_message, meta\n",
        "        summarization = result.get(\"summarization\")\n",
        "        crm_message = result.get(\"crm_message\")\n",
        "        return summarization, crm_message, {}\n",
        "    if isinstance(result, (list, tuple)) and len(result) >= 2:\n",
        "        summarization, crm_message = result[0], result[1]\n",
        "        return summarization, crm_message, {}\n",
        "    if isinstance(result, str):\n",
        "        try:\n",
        "            parsed = json.loads(result)\n",
        "        except json.JSONDecodeError as exc:\n",
        "            raise ValueError(f\"Unexpected pipeline output: {result}\") from exc\n",
        "        return _extract_pipeline_output(parsed)\n",
        "    raise ValueError(f\"Unexpected pipeline output: {result}\")\n",
        "\n",
        "\n",
        "def _parse_stdout_payload(stdout_text):\n",
        "    for line in reversed(stdout_text.splitlines()):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        if not line.startswith(\"{\") or not line.endswith(\"}\"):\n",
        "            continue\n",
        "        try:\n",
        "            return json.loads(line)\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "    raise ValueError(\"Pipeline did not return a usable payload.\")\n",
        "\n",
        "\n",
        "def _run_pipeline_via_argv(pipeline_main, row):\n",
        "    argv = [\n",
        "        \"run_qwen_exaone_pipeline.py\",\n",
        "        \"--persona\",\n",
        "        str(row[\"persona\"]),\n",
        "        \"--brand\",\n",
        "        row[\"brand\"],\n",
        "        \"--product\",\n",
        "        row[\"product\"],\n",
        "        \"--stage_index\",\n",
        "        str(row[\"stage_index\"]),\n",
        "        \"--style_index\",\n",
        "        str(row[\"style_index\"]),\n",
        "        \"--is_event\",\n",
        "        \"1\" if row.get(\"is_event\", False) else \"0\",\n",
        "    ]\n",
        "    buf = StringIO()\n",
        "    old_argv = sys.argv\n",
        "    try:\n",
        "        sys.argv = argv\n",
        "        with redirect_stdout(buf):\n",
        "            result = pipeline_main()\n",
        "    finally:\n",
        "        sys.argv = old_argv\n",
        "    if result is not None:\n",
        "        return result\n",
        "    return _parse_stdout_payload(buf.getvalue())\n",
        "\n",
        "\n",
        "def _run_pipeline(pipeline_main, row):\n",
        "    params = {\n",
        "        \"persona\": row[\"persona\"],\n",
        "        \"brand\": row[\"brand\"],\n",
        "        \"product\": row[\"product\"],\n",
        "        \"stage_index\": row[\"stage_index\"],\n",
        "        \"style_index\": row[\"style_index\"],\n",
        "        \"is_event\": row.get(\"is_event\", False),\n",
        "    }\n",
        "    try:\n",
        "        sig = inspect.signature(pipeline_main)\n",
        "    except (TypeError, ValueError):\n",
        "        sig = None\n",
        "\n",
        "    if sig is not None and len(sig.parameters) == 0:\n",
        "        return _run_pipeline_via_argv(pipeline_main, row)\n",
        "\n",
        "    try:\n",
        "        return pipeline_main(**params)\n",
        "    except TypeError:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        if sig is not None and len(sig.parameters) == 1:\n",
        "            return pipeline_main(row)\n",
        "    except TypeError:\n",
        "        pass\n",
        "\n",
        "    ordered = [\n",
        "        params[\"persona\"],\n",
        "        params[\"brand\"],\n",
        "        params[\"product\"],\n",
        "        params[\"stage_index\"],\n",
        "        params[\"style_index\"],\n",
        "        params[\"is_event\"],\n",
        "    ]\n",
        "    return pipeline_main(*ordered)\n",
        "\n",
        "\n",
        "def _collect_candidates(inference_pipeline, row, num_candidates):\n",
        "    summarization = None\n",
        "    candidates = []\n",
        "    summary_mismatch = False\n",
        "    for attempt in range(1, num_candidates + 1):\n",
        "        _log(f\"  [Attempt {attempt}/{num_candidates}] Running pipeline\")\n",
        "        result = _run_pipeline(inference_pipeline, row)\n",
        "        s, message, meta = _extract_pipeline_output(result)\n",
        "        if summarization is None and s:\n",
        "            summarization = s\n",
        "        elif s and summarization and s != summarization:\n",
        "            summary_mismatch = True\n",
        "        if isinstance(message, str) and message.strip():\n",
        "            candidates.append({\"text\": message.strip(), \"meta\": meta})\n",
        "    if summary_mismatch:\n",
        "        _log(\"  [Warn] Qwen draft differs across candidates; using the first one.\")\n",
        "    return summarization, candidates\n",
        "\n",
        "\n",
        "def generate_dpo_data(csv_path, output_path, max_rows=None, num_candidates=4):\n",
        "    inference_pipeline = _import_pipeline_main()\n",
        "    records = _load_existing_records(output_path)\n",
        "\n",
        "    PAIRS_PER_ROW = max(1, num_candidates - 1)\n",
        "    start_row = len(records) // PAIRS_PER_ROW\n",
        "\n",
        "    _log(f\"Loaded existing records: {len(records)}\")\n",
        "    _log(f\"Resuming from CSV row index: {start_row}\")\n",
        "\n",
        "    _log(f\"CSV: {csv_path}\")\n",
        "    _log(f\"Output: {output_path}\")\n",
        "    _log(f\"Candidates per row: {num_candidates}\")\n",
        "    _log(f\"Loaded existing records: {len(records)}\")\n",
        "\n",
        "    added = 0\n",
        "    SAVE_EVERY_N_ROWS = 4\n",
        "    processed_rows = 0\n",
        "    for idx, row in enumerate(_load_pairs(csv_path)):\n",
        "        if idx < start_row:\n",
        "          continue\n",
        "        if max_rows is not None and idx >= max_rows:\n",
        "            break\n",
        "\n",
        "        _log(\n",
        "            \"[Row {idx}] persona={persona} brand={brand} product={product} \"\n",
        "            \"stage_index={stage_index} style_index={style_index} is_event={is_event}\".format(\n",
        "                idx=idx,\n",
        "                persona=row[\"persona\"],\n",
        "                brand=row[\"brand\"],\n",
        "                product=row[\"product\"],\n",
        "                stage_index=row[\"stage_index\"],\n",
        "                style_index=row[\"style_index\"],\n",
        "                is_event=row.get(\"is_event\", False),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            summarization, candidates = _collect_candidates(\n",
        "                inference_pipeline, row, num_candidates\n",
        "            )\n",
        "        except Exception as exc:\n",
        "            _log(f\"[Row {idx}] Pipeline error: {exc}\")\n",
        "            continue\n",
        "\n",
        "        meta_for_prompt = candidates[0].get(\"meta\", {}) if candidates else {}\n",
        "        prompt_text = _build_prompt_text(meta_for_prompt, summarization)\n",
        "        if not prompt_text:\n",
        "            _log(f\"[Row {idx}] Empty summarization, skipping\")\n",
        "            continue\n",
        "\n",
        "        _log(f\"[Row {idx}] Raw candidates: {len(candidates)}\")\n",
        "        candidates = _dedupe_candidates(_normalize_candidates(candidates))\n",
        "        _log(f\"[Row {idx}] Deduped candidates: {len(candidates)}\")\n",
        "        if len(candidates) < 2:\n",
        "            _log(f\"[Row {idx}] Not enough candidates, skipping\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            best_idx = _call_gpt(prompt_text, candidates)\n",
        "        except Exception as exc:\n",
        "            _log(f\"[Row {idx}] Evaluator error: {exc}\")\n",
        "            continue\n",
        "\n",
        "        _log(f\"[Row {idx}] Best candidate index: {best_idx}\")\n",
        "        best_text = candidates[best_idx][\"text\"]\n",
        "        for candidate in candidates:\n",
        "            if candidate is candidates[best_idx]:\n",
        "                continue\n",
        "            rejected_text = candidate[\"text\"]\n",
        "            if not rejected_text:\n",
        "                continue\n",
        "            records.append(\n",
        "                {\n",
        "                    \"prompt\": prompt_text,\n",
        "                    \"chosen\": best_text,\n",
        "                    \"rejected\": rejected_text,\n",
        "                }\n",
        "            )\n",
        "            added += 1\n",
        "\n",
        "        # row 1개 처리 완료\n",
        "        processed_rows += 1\n",
        "\n",
        "        if processed_rows % SAVE_EVERY_N_ROWS == 0:\n",
        "          _save_records(output_path, records)\n",
        "          _log(f\"[Checkpoint] Saved after {processed_rows} rows\")\n",
        "\n",
        "    _save_records(output_path, records)\n",
        "    _log(f\"Saved {added} new records to {output_path}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--csv_path\", default=DEFAULT_CSV)\n",
        "    parser.add_argument(\"--output_path\", default=DEFAULT_OUTPUT)\n",
        "    parser.add_argument(\"--max_rows\", type=int, default=None)\n",
        "    parser.add_argument(\"--num_candidates\", type=int, default=4)\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    generate_dpo_data(\n",
        "        args.csv_path,\n",
        "        args.output_path,\n",
        "        args.max_rows,\n",
        "        args.num_candidates,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjfXgCWkr7Jy"
      },
      "id": "EjfXgCWkr7Jy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}