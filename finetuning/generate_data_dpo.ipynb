{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import inspect\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "DEFAULT_CSV = os.path.join(BASE_DIR, \"random_persona_campaign.csv\")\n",
    "DEFAULT_OUTPUT = os.path.join(BASE_DIR, \"finetuning_data_dpo\", \"cycle_01.json\")\n",
    "SRC_DIR = os.path.abspath(os.path.join(BASE_DIR, \"..\", \"src\"))\n",
    "\n",
    "def _log(message):\n",
    "    print(message)\n",
    "\n",
    "\n",
    "def _import_pipeline_main():\n",
    "    if SRC_DIR not in sys.path:\n",
    "        sys.path.insert(0, SRC_DIR)\n",
    "    try:\n",
    "        from run_qwen_exaone_pipeline import main as pipeline_main\n",
    "    except Exception as exc:\n",
    "        raise ImportError(\n",
    "            \"Failed to import main from ../src/run_qwen_exaone_pipeline.py\"\n",
    "        ) from exc\n",
    "    return pipeline_main\n",
    "\n",
    "\n",
    "def _parse_bool(value):\n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "    if value is None:\n",
    "        return False\n",
    "    if isinstance(value, (int, float)):\n",
    "        return bool(value)\n",
    "    text = str(value).strip().lower()\n",
    "    return text in {\"1\", \"true\", \"yes\", \"y\", \"t\"}\n",
    "\n",
    "\n",
    "def _load_pairs(csv_path):\n",
    "    with open(csv_path, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            persona_raw = row.get(\"persona\", \"\").strip()\n",
    "            brand_raw = row.get(\"brand\", \"\").strip()\n",
    "            product_raw = row.get(\"product\", \"\").strip()\n",
    "            stage_raw = row.get(\"stage_index\", \"\").strip()\n",
    "            style_raw = row.get(\"style_index\", \"\").strip()\n",
    "            if not persona_raw or not brand_raw or not product_raw:\n",
    "                continue\n",
    "            if not stage_raw or not style_raw:\n",
    "                continue\n",
    "            try:\n",
    "                persona = int(persona_raw)\n",
    "                stage_index = int(stage_raw)\n",
    "                style_index = int(style_raw)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            yield {\n",
    "                \"persona\": persona,\n",
    "                \"brand\": brand_raw,\n",
    "                \"product\": product_raw,\n",
    "                \"stage_index\": stage_index,\n",
    "                \"style_index\": style_index,\n",
    "                \"is_event\": _parse_bool(row.get(\"is_event\", \"\")),\n",
    "            }\n",
    "\n",
    "\n",
    "def _format_prompt(summarization):\n",
    "    if summarization is None:\n",
    "        return \"\"\n",
    "    if isinstance(summarization, str):\n",
    "        return summarization.strip()\n",
    "    return json.dumps(summarization, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def _candidate_text(candidate):\n",
    "    if isinstance(candidate, dict):\n",
    "        return (\n",
    "            candidate.get(\"text\")\n",
    "            or candidate.get(\"crm_message\")\n",
    "            or candidate.get(\"message\")\n",
    "            or candidate.get(\"content\")\n",
    "        )\n",
    "    return str(candidate)\n",
    "\n",
    "\n",
    "def _normalize_candidates(raw):\n",
    "    if raw is None:\n",
    "        return []\n",
    "    if isinstance(raw, dict):\n",
    "        if \"candidates\" in raw:\n",
    "            raw = raw[\"candidates\"]\n",
    "        elif \"messages\" in raw:\n",
    "            raw = raw[\"messages\"]\n",
    "        elif \"crm_messages\" in raw:\n",
    "            raw = raw[\"crm_messages\"]\n",
    "        elif \"crm_message\" in raw and isinstance(raw[\"crm_message\"], list):\n",
    "            raw = raw[\"crm_message\"]\n",
    "        else:\n",
    "            raw = [raw]\n",
    "    if not isinstance(raw, list):\n",
    "        raw = [raw]\n",
    "\n",
    "    normalized = []\n",
    "    for idx, item in enumerate(raw):\n",
    "        text = _candidate_text(item)\n",
    "        if not text:\n",
    "            continue\n",
    "        normalized.append({\"response_id\": idx, \"text\": text})\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def _dedupe_candidates(items):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for item in items:\n",
    "        text = _candidate_text(item)\n",
    "        if not text:\n",
    "            continue\n",
    "        key = text.strip()\n",
    "        if not key or key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _extract_response_text(data):\n",
    "    if isinstance(data, dict):\n",
    "        output_text = data.get(\"output_text\")\n",
    "        if isinstance(output_text, str) and output_text.strip():\n",
    "            return output_text.strip()\n",
    "\n",
    "        output = data.get(\"output\")\n",
    "        if isinstance(output, list):\n",
    "            parts = []\n",
    "            for item in output:\n",
    "                if not isinstance(item, dict):\n",
    "                    continue\n",
    "                content = item.get(\"content\", [])\n",
    "                if isinstance(content, list):\n",
    "                    for block in content:\n",
    "                        if isinstance(block, dict) and isinstance(block.get(\"text\"), str):\n",
    "                            parts.append(block[\"text\"])\n",
    "                        elif isinstance(block, str):\n",
    "                            parts.append(block)\n",
    "                elif isinstance(content, str):\n",
    "                    parts.append(content)\n",
    "            if parts:\n",
    "                return \"\".join(parts).strip()\n",
    "\n",
    "    raise ValueError(f\"Invalid evaluator response: {data}\")\n",
    "\n",
    "\n",
    "def _call_gpt(prompt_text, candidates):\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY is not set.\")\n",
    "\n",
    "    candidate_lines = []\n",
    "    for idx, candidate in enumerate(candidates):\n",
    "        candidate_lines.append(f\"[{idx}] {candidate.get('text', '')}\")\n",
    "    candidate_block = \"\\n\\n\".join(candidate_lines)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"너는 마케팅 문장 평가자다.\\n\"\n",
    "        \"목표는 “전환 가능성이 더 높은 CRM 메시지”를 고르는 것이다.\\n\\n\"\n",
    "        \"다음 기준으로 두 응답을 비교하라:\\n\"\n",
    "        \"1. 수신자가 실제 행동(클릭/재구매)을 할 가능성\\n\"\n",
    "        \"2. persona와 구매 단계 적합성\\n\"\n",
    "        \"3. 상품·브랜드 핵심 장점 전달력\\n\"\n",
    "        \"4. 불필요한 장식 없이 명확한가\\n\\n\"\n",
    "        \"더 나은 쪽을 선택하라.\"\n",
    "    )\n",
    "    user_prompt = (\n",
    "        \"요약:\\n\"\n",
    "        f\"{prompt_text}\\n\\n\"\n",
    "        \"후보:\\n\"\n",
    "        f\"{candidate_block}\\n\\n\"\n",
    "        \"더 나은 후보의 인덱스만 정수로 반환하라.\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-5-nano\",\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": system_prompt}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": user_prompt}],\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        \"https://api.openai.com/v1/responses\",\n",
    "        data=json.dumps(payload).encode(\"utf-8\"),\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        method=\"POST\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(request, timeout=30) as response:\n",
    "            data = json.loads(response.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as exc:\n",
    "        body = exc.read().decode(\"utf-8\", errors=\"replace\")\n",
    "        raise RuntimeError(f\"OpenAI API error {exc.code}: {body}\") from exc\n",
    "\n",
    "    content = _extract_response_text(data)\n",
    "    match = re.search(r\"-?\\d+\", content)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid evaluator response: {content}\")\n",
    "    choice = int(match.group(0))\n",
    "    if choice < 0 or choice >= len(candidates):\n",
    "        raise ValueError(f\"Evaluator index out of range: {choice}\")\n",
    "    return choice\n",
    "\n",
    "\n",
    "def _load_existing_records(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Expected a list in {path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def _save_records(path, records):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def _extract_pipeline_output(result):\n",
    "    if isinstance(result, dict):\n",
    "        summarization = result.get(\"summarization\")\n",
    "        crm_message = result.get(\"crm_message\")\n",
    "    elif isinstance(result, (list, tuple)) and len(result) >= 2:\n",
    "        summarization, crm_message = result[0], result[1]\n",
    "    elif isinstance(result, str):\n",
    "        try:\n",
    "            parsed = json.loads(result)\n",
    "        except json.JSONDecodeError as exc:\n",
    "            raise ValueError(f\"Unexpected pipeline output: {result}\") from exc\n",
    "        return _extract_pipeline_output(parsed)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected pipeline output: {result}\")\n",
    "    return summarization, crm_message\n",
    "\n",
    "\n",
    "def _parse_stdout_payload(stdout_text):\n",
    "    for line in reversed(stdout_text.splitlines()):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if not line.startswith(\"{\") or not line.endswith(\"}\"):\n",
    "            continue\n",
    "        try:\n",
    "            return json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Pipeline did not return a usable payload.\")\n",
    "\n",
    "\n",
    "def _run_pipeline_via_argv(pipeline_main, row):\n",
    "    argv = [\n",
    "        \"run_qwen_exaone_pipeline.py\",\n",
    "        \"--persona\",\n",
    "        str(row[\"persona\"]),\n",
    "        \"--brand\",\n",
    "        row[\"brand\"],\n",
    "        \"--product\",\n",
    "        row[\"product\"],\n",
    "        \"--stage_index\",\n",
    "        str(row[\"stage_index\"]),\n",
    "        \"--style_index\",\n",
    "        str(row[\"style_index\"]),\n",
    "        \"--is_event\",\n",
    "        \"1\" if row.get(\"is_event\", False) else \"0\",\n",
    "    ]\n",
    "    buf = StringIO()\n",
    "    old_argv = sys.argv\n",
    "    try:\n",
    "        sys.argv = argv\n",
    "        with redirect_stdout(buf):\n",
    "            result = pipeline_main()\n",
    "    finally:\n",
    "        sys.argv = old_argv\n",
    "    if result is not None:\n",
    "        return result\n",
    "    return _parse_stdout_payload(buf.getvalue())\n",
    "\n",
    "\n",
    "def _run_pipeline(pipeline_main, row):\n",
    "    params = {\n",
    "        \"persona\": row[\"persona\"],\n",
    "        \"brand\": row[\"brand\"],\n",
    "        \"product\": row[\"product\"],\n",
    "        \"stage_index\": row[\"stage_index\"],\n",
    "        \"style_index\": row[\"style_index\"],\n",
    "        \"is_event\": row.get(\"is_event\", False),\n",
    "    }\n",
    "    try:\n",
    "        sig = inspect.signature(pipeline_main)\n",
    "    except (TypeError, ValueError):\n",
    "        sig = None\n",
    "\n",
    "    if sig is not None and len(sig.parameters) == 0:\n",
    "        return _run_pipeline_via_argv(pipeline_main, row)\n",
    "\n",
    "    try:\n",
    "        return pipeline_main(**params)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if sig is not None and len(sig.parameters) == 1:\n",
    "            return pipeline_main(row)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    ordered = [\n",
    "        params[\"persona\"],\n",
    "        params[\"brand\"],\n",
    "        params[\"product\"],\n",
    "        params[\"stage_index\"],\n",
    "        params[\"style_index\"],\n",
    "        params[\"is_event\"],\n",
    "    ]\n",
    "    return pipeline_main(*ordered)\n",
    "\n",
    "\n",
    "def _collect_candidates(inference_pipeline, row, num_candidates):\n",
    "    summarization = None\n",
    "    candidates = []\n",
    "    for attempt in range(1, num_candidates + 1):\n",
    "        _log(f\"  [Attempt {attempt}/{num_candidates}] Running pipeline\")\n",
    "        result = _run_pipeline(inference_pipeline, row)\n",
    "        s, message = _extract_pipeline_output(result)\n",
    "        if summarization is None and s:\n",
    "            summarization = s\n",
    "        if isinstance(message, str) and message.strip():\n",
    "            candidates.append({\"text\": message.strip()})\n",
    "    return summarization, candidates\n",
    "\n",
    "\n",
    "def generate_dpo_data(csv_path, output_path, max_rows=None, num_candidates=4):\n",
    "    inference_pipeline = _import_pipeline_main()\n",
    "    records = _load_existing_records(output_path)\n",
    "    _log(f\"CSV: {csv_path}\")\n",
    "    _log(f\"Output: {output_path}\")\n",
    "    _log(f\"Candidates per row: {num_candidates}\")\n",
    "    _log(f\"Loaded existing records: {len(records)}\")\n",
    "\n",
    "    added = 0\n",
    "    for idx, row in enumerate(_load_pairs(csv_path)):\n",
    "        if max_rows is not None and idx >= max_rows:\n",
    "            break\n",
    "\n",
    "        _log(\n",
    "            \"[Row {idx}] persona={persona} brand={brand} product={product} \"\n",
    "            \"stage_index={stage_index} style_index={style_index} is_event={is_event}\".format(\n",
    "                idx=idx,\n",
    "                persona=row[\"persona\"],\n",
    "                brand=row[\"brand\"],\n",
    "                product=row[\"product\"],\n",
    "                stage_index=row[\"stage_index\"],\n",
    "                style_index=row[\"style_index\"],\n",
    "                is_event=row.get(\"is_event\", False),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            summarization, candidates = _collect_candidates(\n",
    "                inference_pipeline, row, num_candidates\n",
    "            )\n",
    "        except Exception as exc:\n",
    "            _log(f\"[Row {idx}] Pipeline error: {exc}\")\n",
    "            continue\n",
    "\n",
    "        prompt_text = _format_prompt(summarization)\n",
    "        if not prompt_text:\n",
    "            _log(f\"[Row {idx}] Empty summarization, skipping\")\n",
    "            continue\n",
    "\n",
    "        _log(f\"[Row {idx}] Raw candidates: {len(candidates)}\")\n",
    "        candidates = _dedupe_candidates(_normalize_candidates(candidates))\n",
    "        _log(f\"[Row {idx}] Deduped candidates: {len(candidates)}\")\n",
    "        if len(candidates) < 2:\n",
    "            _log(f\"[Row {idx}] Not enough candidates, skipping\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            best_idx = _call_gpt(prompt_text, candidates)\n",
    "        except Exception as exc:\n",
    "            _log(f\"[Row {idx}] Evaluator error: {exc}\")\n",
    "            continue\n",
    "\n",
    "        _log(f\"[Row {idx}] Best candidate index: {best_idx}\")\n",
    "        best_text = candidates[best_idx][\"text\"]\n",
    "        for candidate in candidates:\n",
    "            if candidate is candidates[best_idx]:\n",
    "                continue\n",
    "            rejected_text = candidate[\"text\"]\n",
    "            if not rejected_text:\n",
    "                continue\n",
    "            records.append(\n",
    "                {\n",
    "                    \"prompt\": prompt_text,\n",
    "                    \"chosen\": best_text,\n",
    "                    \"rejected\": rejected_text,\n",
    "                }\n",
    "            )\n",
    "            added += 1\n",
    "\n",
    "    _save_records(output_path, records)\n",
    "    _log(f\"Saved {added} new records to {output_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--csv_path\", default=DEFAULT_CSV)\n",
    "    parser.add_argument(\"--output_path\", default=DEFAULT_OUTPUT)\n",
    "    parser.add_argument(\"--max_rows\", type=int, default=None)\n",
    "    parser.add_argument(\"--num_candidates\", type=int, default=4)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    generate_dpo_data(\n",
    "        args.csv_path,\n",
    "        args.output_path,\n",
    "        args.max_rows,\n",
    "        args.num_candidates,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
